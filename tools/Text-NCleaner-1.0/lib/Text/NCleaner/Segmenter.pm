# -*-cperl-*-
package Text::NCleaner::Segmenter;

use warnings;
use strict;

=head1 NAME

Text::NCleaner::Segmenter - Paragraph segmentation of HTML and text files

=cut

use Carp;
use FileHandle;
use File::Slurp;
use File::Temp;

=head1 SYNOPSIS

This is an internal helper module for B<Text::NCleaner>.  It converts HTML
files to plain text (using the terminal browser B<lynx> as an external backend),
performs some basic cleanup, splits them into paragraph-sized segments, and
classifies segments as headers (C<< <h> >>), list items (C<< <l> >>) or standard
text paragraphs (C<< <p> >>).  The module can also process plain text files 
(generated by a Web browser), which have to be in UTF-8 encoding if they contain
non-ASCII characters.  HTML files are auto-detected based on their filename
extensions (C<.html>, C<.xhtml> or C<.htm>).

    use Text::NCleaner::Segmenter;

    my $text = new Segmenter "web_page.html";

    foreach my $par ($text->get_segments) { ... }
        # $par starts with <p>, <h> or <l>

    while (my $par = $text->get_segment) { ... }

=head1 METHODS

=over 4

=item I<$text> = B<new> Text::NCleaner::Segmenter I<$filename>;

Reads file I<$filename> into memory. If I<$filename> ends in the extension
C<.html>, C<.xhtml> or C<.htm> (case-insensitive), the file is assumed to be
in HTML format and automatically converted to plain text using B<lynx>.
Otherwise, it is assumed to be the text dump of a Web page in UTF-8 encoding.
Some simple cleanup is performed on the text, then it is split into
pargraph-like units that can be accessed through the B<get_segment> and
B<get_segments> methods.

=cut

sub new ( $$ ) {
  croak "Usage: \$handle = new Text::NCleaner::Segmenter \$file"
    unless @_ == 2;
  my $class = shift;
  my $filename = shift;
  my $debug = 0;

  my $self = bless {}, $class;
  $self->{FILENAME} = $filename;

  my @lines = ();
  my $fh = new FileHandle;

  if ($filename =~ /\.(x?html?)$/i) {
    my $html = "";		# HTML file -> do some HTML-level cleanup
    {
      open($fh, $filename)
	or croak "Can't read file '$filename': $!";
      local($/) = undef;
      $html = <$fh>;
      $fh->close;
    }
    $html =~ s/<!--.*?-->//sg;	     # remove comments
    $html =~ s/<script(\s+[^>]*)?>.*?<\/script>//sgi; # try to remove Java scripts
    $html =~ s/<(img|embed)\s+[^>]*>//gi;		   # delete all images
    $html =~ s/<(embed|iframe)(\s*[^>]*)?>.*?<\1>//sgi;	   # remove embedded media and iframes
    $html =~ s/<li(\s+[^>]*)?>/$& \&lt;l\&gt; /gi;	   # mark <li> items with <l> tag
    $html =~ s/<h[0-9](\s+[^>]*)?>/$& \&lt;h\&gt; /gi;	   # mark <hX> items with <h> tag
    $html =~ s/<br(\s*\/)?>/ \&lt;p\&gt; /gi;              # interpret <br> line breaks as segment boundaries and mark with <p> tag
    my $tempfile = new File::Temp SUFFIX => ".html", UNLINK => 1;
    print $tempfile $html;
    $tempfile->close;
    my $lynx_cmd = "lynx -dump -force_html -nolist -display_charset=utf8 -width=1000000 $tempfile |";
    open($fh, $lynx_cmd)
      or die "Can't open Lynx pipe with temporary file '$tempfile': $!";
    @lines = <$fh>; # slurp entire file for cleanup and paragraph segmentation
    $fh->close;
    undef $tempfile;
  }
  else {
    open($fh, $filename)
      or croak "Can't read file '$filename': $!";
    @lines = <$fh>; # slurp entire file for cleanup and paragraph segmentation
    $fh->close;
  }

  if ($debug) {
    print "=" x 80, "\n";
    foreach (@lines) { print }
    print "=" x 80, "\n";
  }

  ## delete URL line if we're processing a gold standard file
  @lines = grep { not /^\s*URL/ } @lines;

  ## perform some heuristic cleanup of the text file
  @lines = grep {
    local $_ = $_; s/<.>/ /g; # remove segment marker tags from localized copy of line
    tr[|][|] < 3 and tr[>][>] < 3 and tr[<][<] < 3 and tr[&][&] < 3
  } @lines;
  @lines = grep { my @F = split /\s+-\s+/; @F < 4 } @lines;
  my $text = join("", @lines);	 # join entire text for quick substitutions;

  if ($debug) {
   print "=" x 80, "\n";
   print $text;
   print "=" x 80, "\n";
 }

  $text =~ s/_{2,}|-{5,}//g;	 # form fields and separator lines
  $text =~ s/^ \s* ( [*+-] | ( [0-9]+ | [a-z] | [ivxlc]+ ) [.)] ) \s+ /<l> /gmxi;  # heuristic to identify list items
  $text =~ s/^\s*$/<p>/gm;  	# empty lines indicate new paragraphs

  ## now remove all linebreaks, normalise whitespace, and split on segment markers
  $text = "<p> ".$text;
  $text =~ s/\s+/ /gs;

  if ($debug) {
    print $text;
    print "=" x 80, "\n";
  }

  my @segments = split /(?=<[plh]>)/, $text;
  @segments = grep { s/^\s+//; s/\s+$//; not (/^$/ or /^<[plh]>$/) } @segments;

  $self->{SEGMENTS} = [ @segments ];  # store text segments for sequential readout

  return $self;
}

=item I<$par> = I<$text>->B<get_segment>

Returns next text segment, or B<undef> if all segments have been processed.
The text I<$par> is in UTF-8 encoding (but I<not> flagged as a Unicode string)
and starts with C<< <p> >>, C<< <h> >> or C<< <l> >>, depending on the type of
the paragraph.

=cut

sub get_segment {
  my $self = shift;

  return undef unless @{$self->{SEGMENTS}};
  return shift @{$self->{SEGMENTS}};
}

=item I<@paragraphs> = I<$text>->B<get_segments>

Returns a list of all text segments, as if calling B<get_segments> repeatedly.

=cut

sub get_segments {
  my $self = shift;

  return @{ $self->{SEGMENTS} };
}

=back

=head1 AUTHOR

Stefan Evert C<< <stefan.evert@uos.de> >>

=head1 COPYRIGHT & LICENSE

Copyright (C) 2008 by Stefan Evert, all rights reserved.

This program is free software; you can redistribute it and/or modify it
under the same terms as Perl itself.

=cut

1; # End of Text::NCleaner::Segmenter
